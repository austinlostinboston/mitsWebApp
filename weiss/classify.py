"""
TODO(wenjunw@cs.cmu.edu):
- Reconsider the type words
"""
import pickle
import datetime
import nltk

from feature import *
from liblinearutil import *

class Classifier(object):
    def __init__(self):
        self.model = self._get_model()
        self.stopwords = stopword('english.stp')
        self.feature_arg = parse_options('-uni -pos2')
        self.feature_list = self._get_feature_list()
        self.type_words = self._set_type_words()
        self.labels = [1,2,3,4,5,6,7,8]

    def _get_model(self):
        date = str(datetime.date.today())
        m = load_model('model_'+date)
        if m == None:
            date = str(datetime.date.fromordinal(datetime.date.today().toordinal()-1))
            m = load_model('model_'+date)

        return m

    def _get_feature_list(self):
        date = str(datetime.date.today())
        try:
            infile = open('features_'+date)
        except IOError:
            date = str(datetime.date.fromordinal(datetime.date.today().toordinal()-1))
            infile = open('features_'+date)

        feature_list = pickle.load(infile)
        return feature_list

    def _convert_query_to_dictionary(self, query):
        """Convert each user query to the format required by LibLINEAR

        Args and Need: 
            query: the raw query, like 'What do people think of ?'
            self.feature_list: a list of unique features generated by function feature_generator
    
        Return:
            Convert user's query: store information in a dictionary, 
            which is a member of a list. 
        """
        features = feature_generator(query, self.stopwords, self.feature_arg)
        onerow = {}
        for f in features:
            onerow[self.feature_list.index(f)+1] = 1

        return [onerow]

    def _classify(self, query):
        x = self._convert_query_to_dictionary(query)
        p_label, p_val = predict(self.labels, x, self.model, '-b 0')
        if p_val[0][int(p_label[0])-1] == 0:
            p_label[0] = -1

        return int(p_label[0]) # API changes here

    def action_info(self, query):
        arguments = {}
        arguments['aid'] = self._classify(query)

        
        if arguments['aid'] == 7:
            self._entity_recognition(query,arguments)
        elif arguments['aid'] == 8:
            self._type_recognition(query,arguments)

        return arguments

    def _entity_recognition(self, query, arguments):
        tokens = nltk.word_tokenize(query)
        tags = nltk.pos_tag(tokens)
        entities = nltk.chunk.ne_chunk(tags)

        tuples = []
        trees = []
        for i in entities:
            if isinstance(i,tuple):
                if (i[1][:2] == 'NN' or i[1][:2] == 'JJ'
                    and i[0].lower() not in self.stopwords 
                    and i[0].rstrip('s') not in self.type_words['movie']
                    and i[0].rstrip('s') not in self.type_words['article'] 
                    and i[0].rstrip('s') not in self.type_words['restaurant']):
                    tuples.append(i[0])
            elif isinstance(i,nltk.tree.Tree):
                phrase = []
                for element in i:
                    if element[0].lower() not in self.stopwords:
                        phrase.append(element[0])
                if len(phrase) > 0:
                    trees.append(' '.join(phrase))

        if len(trees) > 0:
            arguments['keywords'] = '#'.join(trees).strip('#')
        else:
            arguments['keywords'] = '#'.join(tuples).strip('#')
    
    def _set_type_words(self):
        topic = {}
        topic['movie'] = set(['cinema','show','film','picture','cinematograph',
            'videotape','flick','pic','cine','cinematics','photodrama',
            'photoplay','talkie','flicker','DVD','movie'])
        topic['article'] = set(['report','announcement','story','account',
            'newscast','headlines','press','communication','talk','word',
            'communique','bulletin','message','dispatch','broadcast',
            'statement','intelligence','disclosure','revelation',
            'gossip','dispatch','news','article'])
        topic['restaurant'] = set(['bar','cafeteria','diner','dining','saloon','coffeehouse',
            'canteen','chophouse','drive-in','eatery','grill','lunchroom','inn',
            'pizzeria','hideaway','cafe','charcuterie','deli','restaurant'])
        return topic

    def _type_recognition(self, query, arguments):
        tokens = nltk.word_tokenize(query)
        if tokens[-1].rstrip('s') in movie or tokens[-2].rstrip('s') in self.type_words['article']:
            arguments['tid'] = 1
        elif tokens[-1].rstrip('s') in movie or tokens[-2].rstrip('s') in self.type_words['restaurant']:
            arguments['tid'] = 2
        elif tokens[-1].rstrip('s') in movie or tokens[-2].rstrip('s') in self.type_words['movie']:
            arguments['tid'] = 3